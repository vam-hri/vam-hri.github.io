<!DOCTYPE html>

<html lang="en">

<head>
  <title>VAM-HRI 2024 Program</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-giJF6kkoqNQ00vy+HMDP7azOuL0xtbfIcaT9wjKHr8RbDVddVHyTfAAsrekwKmP1" crossorigin="anonymous">
  <link href="../assets/css/main.css" rel="stylesheet">

  <!-- Fontawesome v5.3.1 -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css"
    integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
  <!-- jQuery -->

  <script src="../assets/js/jquery-3.2.1.min.js"></script>
  <script src="../assets/js/main.js"></script>
  <script src="https://www.w3schools.com/lib/w3.js"></script>
</head>

<body class="container">

  <h5 class="text-danger mt-5 d-flex justify-content-between align-items-center">VAM-HRI 2025 Program
    <a href="../"><i class="fas fa-home text-danger"></i></a>
  </h5>
  <hr class="bg-danger">

  <div class="list-group mb-5">
    <p>
      <strong>Lightning Talk / Poster Info:</strong>
	  <ul>
      <li>
        7 minute talks
      </li>
      <li>
        Group&nbsp; Q&amp;A for 15 minutes
<ul>
</ul>
      </li>
      <li>
        Visuals (videos/gifs/images) are recommended
      </li>
      <li>
        We recommend you include a slide about feedback you would like from listeners at the workshop.
      </li>
	  <li>
	  <b>If you are presenting in-person,  you may also prepare a poster with the dimensions 24"x36"</b>
	  </li>
	  </ul>
    </p>
  </div>

  <div class="list-group mb-5">
    <p>
      <strong>Workshop Info:</strong>
	  <ul>
	  <li><b>In-Person:</b></li>
	  <ul>
      <li>
        Conference Venue: Convention Centre Place, South Wharf Victoria 3006, Australia. 
      </li>
      <li>
        Workshop Room: 102
      </li>
	  </ul>
	  <li><b>Remotely:</b></li>
	  <ul>
	  <li>
        Zoom Room: <a href="https://qut.zoom.us/j/87675614867?pwd=r6MK5EHR6PBQ6kr8CY953IawKQ5GFg.1" target="_blank">&nbsp;Link here</a>
      </li>
	  <li>
	    Time zone: <a href="https://time.is/Melbourne" target="_blank">Melbourne, Australia</a> (GMT+11)
	  </li>
	  </ul>
	  </ul>
    </p>
  </div>

  <div class="list-group mb-5">
    <li class="list-group-item list-group-item-action list-group-item-primary active">
      <div class="d-flex w-100 justify-content-between">
        <small>March 3 | 09:00 AM - 12:30 PM </small>
      </div>
    </li>
    <li class="list-group-item list-group-item-dark">
      <div class="d-flex w-100 justify-content-between">
        <h5 class="mb-1">Intro + Meet someone new!</h5>
        <small>09:00 AM | 10 min</small>
      </div>
    </li>
    
    	
	
	
	<li class="list-group-item invited">
      <div class="d-flex w-100 justify-content-between">
        <h5 class="mb-1">Keynote + Q&A: <small></small></h5>
        <small>09:10 AM | 40 min</small>
      </div>
      <p>
        <!-- Talk description paragraph -->
      </p>
      <small>Wafa Johal is an Associate Professor at University of Melbourne. Her field of research is at the crossing between robotics, AI and HCI, as she works on enabling robots to interact autonomously and naturally with humans.Her research aims at creating acceptable and useful assistive robot interactions using social signal processing, affective and cognitive reasoning. Her latest work investigated the use of tangible robots in education and rehabilitation.</small>
      <div class="row row-cols-1 row-cols-md-3 mb-3 text-center">

        <div class="col-12 col-lg-3 p-3 member">
          <div class="card">
            <div class="container pt-3" style="text-align: center;">
              <img class="img-circle" src="../assets/images/keynote/WafaJ.jpg" width="50%" height="auto">
            </div>
            <div class="card-body">
              <h5 class="card-title mb-2">Wafa Johal</h5>
              <p class="card-subtitle mb-3 text-muted">Associate Professor at University of Melbourne</p>
              <a href="https://zhaohanphd.com/" target="_blank" class="btn btn-outline-dark">Home</a>
            </div>
          </div>
        </div>
    </li>
	
	<li class="list-group-item list-group-item-dark">
      <div class="d-flex w-100 justify-content-between">
        <h5 class="mb-1">Lightning Talk Group 1 and Group Q&A</h5>
        <small>04:50 PM MST | 50 min</small>
      </div>
    </li>
	<li class="list-group-item">
      <b>Paper #11: To Err is Humanoid; to Collaborate, Divine: A Transitional Reality Interface for Error Replay and Correction in Industrial Robotics</b>
      <a href="https://openreview.net/pdf?id=UCdZm1o2SK" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Lorian Marshall, Jordan Allspaw, Holly A. Yanco
    <li class="list-group-item">
      <b>Paper #2: Enhancing Shared Control for Telepresence in Dynamic Environments using Large Language </b>
      <a href="https://openreview.net/attachment?id=Z2mh4OdDXX&name=pdf" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Manali Jain, Aditya Sanjiv Kanade, Bijo Sebastian, Manivannan Muniyandi 
    </li>
	<li class="list-group-item">
      <b>Paper #1: MiXR-Interact: Mixed Reality Interaction Dataset for Gaze, Hand, and Body</b>
      <a href="https://openreview.net/pdf?id=ssIR7qGfOw" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Natnael Berhanu Takele, Donatien Delehelle, Yaesol Kim, Yonas Teodros Tefera, Nikhil Deshpande, Darwin G Caldwell, Jesus Ortiz, Carmine Tommaso Recchiuto 
    </li>
	<li class="list-group-item">
      <b>Paper #4: SoftBiT: Soft Bimanual Teleoperation with Proprioceptive Visual Augmentation</b>
      <a href="https://openreview.net/attachment?id=Eq5n24wGqO&name=pdf" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Tai Inui, Uksang Yoo, Jeffrey Ichnowski, Jean Oh
    </li>
	<li class="list-group-item">
      <b>Paper #5: Mixed Reality Meets Robotic Systems: A Hololens2-Enabled Waypoint Navigation Interface</b>
      <a href="https://openreview.net/attachment?id=8vc9Q70pnf&name=pdf" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Albus Fang, Xiaomeng Xu, Yanran Lin, Alia Gilbert, Dimitra Panagou
    </li>
	

	<li class="list-group-item list-group-item-dark">
      <div class="d-flex w-100 justify-content-between">
        <h5 class="mb-1">Coffee Break and Demo </h5>
        <small>10:40 AM | 20 min</small>
      </div>
    </li>
	  
	  <li class="list-group-item list-group-item-dark">
      <div class="d-flex w-100 justify-content-between">
        <h5 class="mb-1">Lightning Talk Group 2 and Group Q&A</h5>
        <small>11:00 AM | 60 min</small>
      </div>
    </li>
	<li class="list-group-item">
      <b>Paper #6: Usability Study of VR Interfaces for Learning from Demonstrations in Bimanual Tasks</b>
      <a href="https://openreview.net/attachment?id=gMqlMZCU4z&name=pdf" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Jeffrey Saber, Kim Baraka, Muhan Hou
    <li class="list-group-item">
      <b>Paper #3: Enhancing Robotic Manipulation: AR-Powered Data Collection for Learning from Demonstration </b>
      <a href="https://openreview.net/attachment?id=XkZwSCP1vd&name=pdf" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Thilina Tharanga Malagalage Don, Ehsan Asadi
    </li>
	<li class="list-group-item">
      <b>Paper #10: Augmented Reality for Human Decision Making and Human-Robot Collaboration: A Case Study in Gasket Room in Manufacturing</b>
      <a href="https://openreview.net/attachment?id=omVqdI3ZOd&name=pdf" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Yuan Liu 
    </li>
	<li class="list-group-item">
      <b>Paper #7: LLM-Supported Safety Annotation in High-Risk Environments</b>
      <a href="https://openreview.net/attachment?id=Ewg3WsMBRv&name=pdf" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Mohammad Eskandari, Murali Krishna Varma Indukuri, Stephanie M. Lukin, Cynthia Matuszek
    </li>
	<li class="list-group-item">
      <b>Paper #9: User-Centric Mixed Reality Interventions for Parkinsonâ€™s Tremor Management: A Path Toward Digital Therapeuticse</b>
      <a href="https://openreview.net/attachment?id=jy8FfbQGey&name=pdf" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Xinjun Li, Zhenhong Lei
    </li>
	  <li class="list-group-item">
      <b>Paper #8: A Controller for Robots to Autonomously Control Fog Machines</b>
      <a href="https://openreview.net/attachment?id=DCcX6S0s5n&name=pdf" target="_blank"><span class="badge badge-light badge-pill"><i
            class="fas fa-download text-primary"></i></span></a>
      <br>
      Adrian Lozada, Villa Keth, Uthman Tijani, Michael Klein, Zhao Han
    </li>
	  <li class="list-group-item list-group-item-dark">
      <div class="d-flex w-100 justify-content-between">
        <h5 class="mb-1">Demo Session</h5>
        <small>12:00 PM MST | 25 min</small>
      </div>
    </li>
	 

	
    <li class="list-group-item list-group-item-dark">
      <div class="d-flex w-100 justify-content-between">
        <h5 class="mb-1">Closing</h5>
        <small>12:25 PM MST | 5 min</small>
      </div>
    </li>
  </div>
  


  </div>


</body>

  <footer class="pt-4 my-md-5 pt-md-5 border-top">
    <div class="row">
      <div class="col-12 col-md">
        <img class="mb-2" src="../assets/images/logo_2025.png" width="100" height="auto">
        <small class="d-block mb-3 text-muted">&copy; 2018-2024</small>
      </div>
      <div class="col-6 col-md">
        <h5>History</h5>
        <ul class="list-unstyled text-small">
			<li><a class="link-secondary" href="../previous/2024">2024</a></li>
          <li><a class="link-secondary" href="../previous/2023">2023</a></li>
          <li><a class="link-secondary" href="../previous/2022">2022</a></li>
          <li><a class="link-secondary" href="../previous/2021">2021</a></li>
          <li><a class="link-secondary" href="../previous/2020">2020</a></li>
          <li><a class="link-secondary" href="../previous/2019#">2019</a></li>
          <li><a class="link-secondary" href="../previous/2018">2018</a></li>
        </ul>
      </div>
      <div class="col-6 col-md">
        <h5>Resources</h5>
          <ul class="list-unstyled text-small">
            <li><a class="link-secondary" href="https://humanrobotinteraction.org/2025/full-papers/"
                target="_blank">Author Template</a></li>
            <li><a class="link-secondary" href="https://humanrobotinteraction.org/2025/" target="_blank">HRI 2025</a>
          </li>
        </ul>
      </div>
      <div class="col-6 col-md">
        <h5>Contact</h5>
        <ul class="list-unstyled text-small">
          <li><a class="link-secondary" href="mailto:vam.hri@gmail.com">Email</a></li>
        </ul>
      </div>
    </div>
  </footer>

</html>
